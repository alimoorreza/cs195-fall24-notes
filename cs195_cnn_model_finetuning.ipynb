{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alimoorreza/cs195-fall24-notes/blob/main/cs195_cnn_model_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJrUI0I4uVJ"
      },
      "source": [
        "# CS195: Day08\n",
        "\n",
        "### CS195: Computer Vision, Fall 2024\n",
        "\n",
        "Wednesday, September 25, 2024\n",
        "\n",
        "ðŸ“† [Course Schedule](https://analytics.drake.edu/~reza/teaching/cs195_fall24/cs195_schedule.html) | ðŸ“œ [Syllabus](https://analytics.drake.edu/~reza/teaching/cs195_fall24/cs195_syllabus_fall24.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdp5xYYXHltc",
        "outputId": "c484b747-c87e-46bd-b393-df559d27448e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpvuEwrzrVe8"
      },
      "source": [
        "## __Put the Model on Training Device (GPU or CPU)__\n",
        "We want to accelerate the training process using graphical processing unit (GPU). Fortunately, in Colab we can access for GPU. You need to enable it from _Runtime-->Change runtime type-->GPU or TPU_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFa7eTujrik7",
        "outputId": "3df12124-51c5-4ba0-f2ff-06faf76da687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# util function:\n",
        "def get_imagenet_mean_std_normalized():\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    return mean, std\n",
        "\n",
        "def load_json_file(file_path):\n",
        "\n",
        "  data = {}\n",
        "  with open(file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "  return data\n",
        "\n",
        "def write_json_file(file_path):\n",
        "\n",
        "  data = {}\n",
        "  with open(file_path, 'w') as file:\n",
        "    data = json.dump(data, file)\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "# check to see if torch.cuda is available, otherwise it will use CPU\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82757Boz0u5T"
      },
      "source": [
        "#__Download the Underwater Dataset for Fine-tuning AlexNet__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDGk01A804vq"
      },
      "source": [
        "- [Underwater Animal Dataset (partial)](https://analytics.drake.edu/~reza/teaching/cs195_fall24/datasets/uws_v1_partial.zip)\n",
        "  - Each image size: __HxWx3__\n",
        "    - Note that these are color images\n",
        "  - Each image is associated with a label from __10 classes__\n",
        "  - Training set of __241__ examples and test set of __60__ examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs195_fall24/datasets/underwater_animals.png\" width=600/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "tEgmNni4psnj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w26ZMYs1vL9"
      },
      "source": [
        "#__Prepare Your Data for Training__\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "TEST_IMAGE_SIZE_W = 227\n",
        "TEST_IMAGE_SIZE_H = 227\n",
        "mean, std         = get_imagenet_mean_std_normalized()\n",
        "print(f\"ImageNet: mean: {mean}, std: {std}\")\n",
        "\n",
        "# CNN architectures such as AlexNet, VGGNet, and ResNet has been pre-trained using the ImageNet dataset.\n",
        "# You need to normalize each image with the given mean and standard deviation before doing the forward-pass on these networks.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((TEST_IMAGE_SIZE_W, TEST_IMAGE_SIZE_H)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std) # ImageNet: mean (R, G, B) and standard deviation (R, G, B)\n",
        "])\n",
        "\n",
        "train_dir       = '/content/drive/MyDrive/cs195_fall24/classification/datasets/uws_v1_partial/train'\n",
        "test_dir        = '/content/drive/MyDrive/cs195_fall24/classification/datasets/uws_v1_partial/test'\n",
        "\n",
        "train_dataset   = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset    = datasets.ImageFolder(test_dir,  transform=transform)\n",
        "\n",
        "N_train         = len(train_dataset)\n",
        "N_test          = len(test_dataset)\n",
        "\n",
        "number_of_classes = 10\n",
        "print(\"Number of classes: \", number_of_classes)\n",
        "print(\"Size of train set:\", N_train)\n",
        "print(\"Size of test set:\",  N_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiih5CTBEEEg",
        "outputId": "28e9c300-8e5e-48ba-d0da-edbfb04067dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageNet: mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]\n",
            "Number of classes:  10\n",
            "Size of train set: 241\n",
            "Size of test set: 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4pTsgDsTEiw"
      },
      "source": [
        "#__Building Convolutional Neural Network (CNN)__\n",
        "\n",
        "Create a network class with two methods:\n",
        "- _init()_\n",
        "- _forward()_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DxGu6AUTW10"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import json\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import os\n",
        "\n",
        "import pdb\n",
        "\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# You can give any name to your new network, e.g., AlexNet.\n",
        "# You should load the pretrained AlexNet model from torchvision.models.\n",
        "# This model was trained on over a million real-world images from ImageNet.\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # download PyTorch's own implementation of AlexNet model trained on ImageNet dataset\n",
        "        net             = models.alexnet(pretrained=True)\n",
        "\n",
        "\n",
        "        # retained weightes for convolutional, pooling, linear layers from AlexNet\n",
        "        self.features   = net.features\n",
        "        self.avgpool    = net.avgpool\n",
        "        self.classifier = net.classifier\n",
        "\n",
        "        # IMPORTANT: \"If you need to fine-tune this network for your own dataset,\n",
        "        # the simplest modification is to replace the last layer in self.classifier with\n",
        "        # the updated AlexNet has the desired number of output classes: 'num_classes'\n",
        "        self.classifier[-1] = nn.Linear(4096, num_classes) # only this last layer's weights will be trained from scratch\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        print(\"shape of input: \", x.shape)\n",
        "        x = self.features(x)\n",
        "        print(\"output shape (self.features): \", x.shape)\n",
        "        x = self.avgpool(x)\n",
        "        print(\"output shape (self.avgpool): \", x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        print(\"output shape (self.classifier): \", x.shape)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlwRblRgmVlv",
        "outputId": "b2876336-097c-425f-a8c1-2a49da4a66f2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device =  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"device = \", device)\n",
        "\n",
        "number_of_classes = 10\n",
        "cnn_model             = AlexNet(number_of_classes)\n",
        "cnn_model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1gTfGDJm-2Z"
      },
      "source": [
        "##__Defining Loss function__\n",
        "\n",
        "- [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)\n",
        "  - useful when training a __classification problem__ with __C__ classes.\n",
        "  - criterion computes the cross entropy loss between input logits and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK1bAAANnLMz"
      },
      "outputs": [],
      "source": [
        "# initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss() # this is useful for multiclass classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Mwh6U1mGev"
      },
      "source": [
        "##__Initializing the Optimizer__\n",
        "\n",
        "Optimiztaion, as we have discussed in previous week, is process of adjusting model parameters to reduce model error in each training step. PyTorch provides a selection of optimization algorithms in the [torch.optim](https://pytorch.org/docs/stable/optim.html) package. Some of them are as follows:\n",
        "- [torch.optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)\n",
        "- [torch.optim..Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)\n",
        "- [torch.optim.RMSprop](https://pytorch.org/docs/stable/generated/torch.optim.RMSprop.html#torch.optim.RMSprop)\n",
        "\n",
        "In addition to selecting the optimizer, we can also select the yperparameters which are refered to as adjustable parameters crucial for controlling the model optimization process. You can influence the training and convergence of the model by tweaking these hyperparameters:\n",
        "- __epochs:__ denotes the number of iterations over the dataset\n",
        "- __batch size:__ represents the quantity of data samples in each iteration propagated through the network before updating the parameters\n",
        "- __learning rate:__ determines the extent of parameter updates made at each batch/epoch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11-Lj-avlzFo"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "batch_size    = 32\n",
        "epochs        = 20\n",
        "# let's use ADAM optimization algorithm for training our model\n",
        "optimizer     = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7yBVqvGmQM1"
      },
      "source": [
        "#__Putting Everything Together for AlexNet__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn0KYm8r1i1i"
      },
      "source": [
        "__Putting Everything Together using our AlexNet Network on our 4-class image recognition Dataset__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE6r3j-71vjK"
      },
      "outputs": [],
      "source": [
        "# Step 1: load the Torch library and other utilities\n",
        "#----------------------------------------------------\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision import models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import pdb\n",
        "\n",
        "# util function:\n",
        "def get_imagenet_mean_std_normalized():\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    return mean, std\n",
        "\n",
        "# check to see if torch.cuda is available, otherwise it will use CPU\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "# Step 2: load the dataset\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "# For fine-tuning with an AlexNet/VGG/ResNet architecture that has been pre-trained using the ImageNet dataset, you need to normalize\n",
        "# each image with the given mean and standard deviation.\n",
        "TEST_IMAGE_SIZE_W = 227\n",
        "TEST_IMAGE_SIZE_H = 227\n",
        "mean, std         = get_imagenet_mean_std_normalized()\n",
        "print(f\"ImageNet: mean: {mean}, std: {std}\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((TEST_IMAGE_SIZE_W, TEST_IMAGE_SIZE_H)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std) # ImageNet: mean (R, G, B) and standard deviation (R, G, B)\n",
        "])\n",
        "\n",
        "'''\n",
        "train_dir       = '/nfs/jolteon/data/ssd/mdreza/drake_teaching/cs195_fall24_classification/datasets/uws_v1_partial/train'\n",
        "test_dir        = '/nfs/jolteon/data/ssd/mdreza/drake_teaching/cs195_fall24_classification/datasets/uws_v1_partial/test'\n",
        "'''\n",
        "\n",
        "train_dir       = '/content/drive/MyDrive/cs195_fall24/classification/datasets/uws_v1_partial/train'\n",
        "test_dir        = '/content/drive/MyDrive/cs195_fall24/classification/datasets/uws_v1_partial/test'\n",
        "\n",
        "\n",
        "train_dataset   = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset    = datasets.ImageFolder(test_dir,  transform=transform)\n",
        "\n",
        "N_train         = len(train_dataset)\n",
        "N_test          = len(test_dataset)\n",
        "\n",
        "number_of_classes = 10                          # Headsup! You should change this to the appropriate number when you fine-tune your model on a different dataset.\n",
        "print(\"Number of classes: \", number_of_classes)\n",
        "print(\"Size of train set:\", N_train)\n",
        "print(\"Size of test set:\",  N_test)\n",
        "\n",
        "\n",
        "# Step 3: Use the AlexNet from above\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "# You can give any name to your new network, e.g., AlexNet.\n",
        "# You should load the pretrained AlexNet model from torchvision.models.\n",
        "# This model was trained on over a million real-world images from ImageNet.\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # download PyTorch's own implementation of AlexNet model trained on ImageNet dataset\n",
        "        net             = models.alexnet(pretrained=True)\n",
        "\n",
        "\n",
        "        # retained weightes for convolutional, pooling, linear layers from AlexNet\n",
        "        self.features   = net.features\n",
        "        self.avgpool    = net.avgpool\n",
        "        self.classifier = net.classifier\n",
        "\n",
        "        # IMPORTANT: \"If you need to fine-tune this network for your own dataset,\n",
        "        # the simplest modification is to replace the last layer in self.classifier with\n",
        "        # the updated AlexNet has the desired number of output classes: 'num_classes'\n",
        "        self.classifier[-1] = nn.Linear(4096, num_classes) # only this last layer's weights will be trained from scratch\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Step 4: Your training and testing functions\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "\n",
        "    size            = len(dataloader.dataset)\n",
        "    num_batches     = len(dataloader)\n",
        "\n",
        "    model.train()                   # set the model to training mode for best practices\n",
        "\n",
        "    train_loss      = 0\n",
        "    correct         = 0\n",
        "    train_pred_all  = []\n",
        "    train_y_all     = []\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # compute prediction and loss\n",
        "\n",
        "        # ----------- putting data into gpu or sticking to cpu ----------\n",
        "        X = X.to(device)     # send data to the GPU device (if available)\n",
        "        y = y.to(device)\n",
        "        # -----------                                         ----------\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch % 2 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "        # compute the accuracy\n",
        "        pred_prob   = softmax(pred)\n",
        "        pred_y \t\t\t= torch.max(pred_prob, 1)[1]\n",
        "        train_correct = (pred_y == y).sum()\n",
        "        correct    += train_correct.data\n",
        "\n",
        "        train_pred_all.append(pred_y) # save predicted output for the current batch\n",
        "        train_y_all.append(y)         # save ground truth for the current batch\n",
        "\n",
        "    train_pred_all = torch.cat(train_pred_all) # need to concatenate batch-wise appended items\n",
        "    train_y_all = torch.cat(train_y_all)\n",
        "\n",
        "    train_loss = train_loss/num_batches\n",
        "    correct    = correct.cpu().numpy()/size\n",
        "\n",
        "    print('Confusion matrix for training set:\\n', confusion_matrix(train_y_all.cpu().data, train_pred_all.cpu().data))\n",
        "    return train_loss, 100*correct\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "\n",
        "    model.eval()                    # set the model to evaluation mode for best practices\n",
        "\n",
        "    size                = len(dataloader.dataset)\n",
        "    num_batches         = len(dataloader)\n",
        "    test_loss, correct  = 0, 0\n",
        "    test_pred_all       = []\n",
        "    test_y_all          = []\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for X, y in dataloader:\n",
        "\n",
        "        # ----------- putting data into gpu or sticking to cpu ----------\n",
        "        X = X.to(device)     # send data to the GPU device (if available)\n",
        "        y = y.to(device)\n",
        "        # -----------                                         ----------\n",
        "\n",
        "        pred = model(X)\n",
        "        test_loss += loss_fn(pred, y).item()\n",
        "\n",
        "        # calculate probability and save the outputs for confusion matrix computation\n",
        "        pred_prob     = softmax(pred)\n",
        "        pred_y        = torch.max(pred_prob, 1)[1]\n",
        "        test_correct  = (pred_y == y).sum()\n",
        "        correct      += test_correct.data\n",
        "\n",
        "        test_pred_all.append(pred_y) # save predicted output for the current batch\n",
        "        test_y_all.append(y)         # save ground truth for the current batch\n",
        "\n",
        "\n",
        "    #pdb.set_trace()\n",
        "    test_pred_all = torch.cat(test_pred_all)\n",
        "    test_y_all = torch.cat(test_y_all)\n",
        "\n",
        "    test_loss = test_loss/num_batches\n",
        "    correct   = correct.cpu().numpy()/size\n",
        "    print(f\"Test Performance: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print('Confusion matrix for test set:\\n', confusion_matrix(test_y_all.cpu().data, test_pred_all.cpu().data))\n",
        "    return test_loss, 100*correct, confusion_matrix(test_y_all.cpu().data, test_pred_all.cpu().data)\n",
        "\n",
        "# Step 5: prepare the DataLoader and select your optimizer and set the hyper-parameters for learning the model from DataLoader\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "cnn_model = AlexNet(number_of_classes)\n",
        "cnn_model.to(device)\n",
        "print(cnn_model)\n",
        "\n",
        "\n",
        "learning_rate     = 1e-4\n",
        "batch_size_val    = 32\n",
        "epochs            = 10\n",
        "loss_fn           = nn.CrossEntropyLoss()\n",
        "optimizer         = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
        "softmax           = nn.Softmax(dim=1) # for calculating the probability of the network prediction. It is used in train_loop() and test_loop().\n",
        "\n",
        "train_dataloader  = DataLoader(train_dataset, batch_size=batch_size_val, shuffle=True)  # shuffle the images in training set during fine-tuning\n",
        "test_dataloader   = DataLoader(test_dataset, batch_size=batch_size_val,  shuffle=False) # you don't need to shuffle test images as they are not used during training\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "test_losses  = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "start_time = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    avg_train_loss, train_accuracy                    = train_loop(train_dataloader, cnn_model, loss_fn, optimizer)\n",
        "    avg_test_loss, test_accuracy, conf_matrix_test    = test_loop(test_dataloader,   cnn_model, loss_fn)\n",
        "    # save the losses and accuracies\n",
        "    train_losses.append(avg_train_loss)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "print(\"AlexNet model has been fine-tuned!\")\n",
        "print(\"Total fine-tuning time: %.3f sec\" %( (time.time()-start_time)) )\n",
        "print(\"Total fine-tuning time: %.3f hrs\" %( (time.time()-start_time)/3600) )\n",
        "\n",
        "# visualizing the loss curves\n",
        "plt.plot(range(1,epochs+1), train_losses)\n",
        "plt.plot(range(1,epochs+1), test_losses)\n",
        "plt.title('AlexNet average losses after each epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6fHfzFT70A0"
      },
      "outputs": [],
      "source": [
        "# visualizing the confusion matrix on the test set after the final epoch\n",
        "dataset_labels = ['Crocodile',  'Dolphin', 'Octopus',   'Otter',  'Penguin', \\\n",
        "                  'Polar_bear', 'Squid',   'Star_fish', 'Turtle', 'Whale'] # datasets.ImageFolder(): assigns labels according to the sorted order of the folder names\n",
        "\n",
        "# option #1: text\n",
        "print(pandas.DataFrame(conf_matrix_test, index = dataset_labels, columns = dataset_labels))\n",
        "\n",
        "# option #2: prettify\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "displ = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_test, display_labels=dataset_labels)\n",
        "displ.plot()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}