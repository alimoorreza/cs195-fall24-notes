{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alimoorreza/cs195-fall24-notes/blob/main/cs195_pytorch_basics_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJrUI0I4uVJ"
      },
      "source": [
        "# CS195: Day04\n",
        "\n",
        "## PyTorch Library\n",
        "\n",
        "### CS195: Computer Vision, Fall 2024\n",
        "\n",
        "Wednesday, September 18th, 2024\n",
        "\n",
        "ðŸ“† [Course Schedule](https://analytics.drake.edu/~reza/teaching/cs195_fall24/cs195_schedule.html) | ðŸ“œ [Syllabus](https://analytics.drake.edu/~reza/teaching/cs195_fall24/cs195_syllabus_sp24.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XC7VEFe4uVh"
      },
      "source": [
        "## Introduction to PyTorch\n",
        "\n",
        "We can use PyTorch Framework to build and train MLPs and other neural networks such as CNN, RNN, LSTM, Transformers. Let's learn the basics of PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch library\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "LwgBlHEvJDEJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Convolution and Pooling Layers using PyTorch"
      ],
      "metadata": {
        "id": "8JllItQfeVFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build a 2D convolution layer**\n",
        "- [nn.Conv2d()](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "  - applies a 2D convolution over an input volume of $(C_{in}â€‹,H_{in},W_{in})$ and produces an output volume of $(C_{out}â€‹,H_{out},W_{out})$   between two adjacent layers.\n",
        "  - to create this, you need to provide the followings:\n",
        "    - __channel_dimension_of_input_layer__ i.e., $C_{in}$\n",
        "    - __channel_dimension_of_output_layer__ i.e., $C_{out}$\n",
        "    - __filter_size__ i.e., $F$\n",
        "\n",
        "  - the other two optional parameters are __stride__: $S=1$ and __padding__: $P=0$, with default values as shown. As discussed in class, PyTorch will calculate internally the sizes of output volume $H_{out}$ and $W_{out}$ from the above mentioned parameter values\n",
        "\n",
        "\n",
        "> For example, let's create a 2D convolution layer by specify the following:\n",
        ">> input volume channels size is 1\n",
        "\n",
        ">> output volume channel size is 32\n",
        "\n",
        ">> each filter has a size of (3x3)\n",
        "\n",
        ">> default stride size is 1\n",
        "\n",
        ">> default padding size is 0"
      ],
      "metadata": {
        "id": "K6snyzopmxi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction of a 2D convolutional layer (useful for feature map learning from the grid layouts of an image)\n",
        "input_volume_channel_first  = 8\n",
        "output_volume_channel_first = 8\n",
        "filter_size                 = 3\n",
        "\n",
        "\n",
        "first_conv_2d               = nn.Conv2d(input_volume_channel_first, output_volume_channel_first, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "#first_conv_2d               = nn.Conv2d(input_volume_channel_first, output_volume_channel_first, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "#relu_activation_1st         = nn.ReLU()\n"
      ],
      "metadata": {
        "id": "WovTledem6Lw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Inspecting the weights of a 2D convolution layer**"
      ],
      "metadata": {
        "id": "J2Vd7i1cOUQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the weights of the convolution filters\n",
        "print(f'Weights: \\n{first_conv_2d.weight.data.shape}')\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "t_v_9SaTOY7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3c407b-b740-43a3-fe64-568fc5dd5a1b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            "torch.Size([8, 8, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights of the convolution filters\n",
        "print(f'Weights: \\n{first_conv_2d.weight.data}')\n",
        "\n",
        "# Print the biases of the the convolution filters\n",
        "print(f'Biases: \\n{first_conv_2d.bias.data}')"
      ],
      "metadata": {
        "id": "9hvzq3qYwS7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's generate a random input for our linear layer and plug it into our layer**"
      ],
      "metadata": {
        "id": "9-8gky6gn2rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random sample tensor of shape (B, C, H, W) for the above 2D convolutional network\n",
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples = 1\n",
        "image_channel     = 8\n",
        "image_height      = 7\n",
        "image_width       = 6\n",
        "\n",
        "random_X              = torch.randn(number_of_samples, image_channel, image_width, image_height)\n",
        "print(f'input shape: \\n{random_X.shape}\\n')\n",
        "#print(f'input numbers: \\n{random_X.numpy()}\\n') # it will produce a large tensor of values\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                = first_conv_2d(random_X)\n",
        "print(f'output shape: \\n{output.data.shape}\\n')\n",
        "#print(f'output layer value: \\n{output.data.numpy()}\\n') # it will produce a large tensor of values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2V0Gyc3oBzz",
        "outputId": "511dd337-2ab5-44a3-a207-58613e70d282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: \n",
            "torch.Size([1, 8, 6, 7])\n",
            "\n",
            "output shape: \n",
            "torch.Size([1, 8, 4, 5])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#1**\n",
        "Create a new 2D convolution layer with the following structure:\n",
        "\n",
        "> its input volume has 3 channels\n",
        "\n",
        "> the output volume will be of 64 channels\n",
        "\n",
        "> each filter has a size of (5x5)\n",
        "\n",
        "> default stride size is 1 (don't need to change that but you are free to explore)\n",
        "\n",
        "> default padding size is 0 (don't need to change that but you are free to explore)\n"
      ],
      "metadata": {
        "id": "a-LTmGiyp566"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "v_taKRZgqBde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#2**\n",
        "\n",
        "> apply a tensor through your 2D convolution layer now.\n",
        "\n",
        "> change the value in torch.manual_seed(0) to something else, generate new inputs, and pass the tensor through your 2D convolution layer.\n",
        "\n",
        "> observe the the output shapes specially (since the values are hard to inspect so we will leave them for later classes)\n",
        "\n",
        "> convince yourself that the shapes you are observing match your hand calculations."
      ],
      "metadata": {
        "id": "QVPRiA7ZqOfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "4hsvGpLUqbSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's add an activation function such as *ReLu(), tanh(), or sigmoid()* after your 2D convolution layer and run the experiment again to see how it changes the outputs.**"
      ],
      "metadata": {
        "id": "BOPOELyQsY1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction of a 2D convolutional layer (useful for feature map learning from the grid layouts of an image)\n",
        "input_volume_channel_first  = 1\n",
        "output_volume_channel_first = 32\n",
        "filter_size                 = 3\n",
        "\n",
        "first_conv_2d               = nn.Conv2d(input_volume_channel_first, output_volume_channel_first, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "relu_activation             = nn.ReLU()\n",
        "sigmoid_activation          = nn.Sigmoid()\n",
        "tanh_activation             = nn.Tanh()\n",
        "\n"
      ],
      "metadata": {
        "id": "DRw_QBK4sdTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using Sigmoid activation function**"
      ],
      "metadata": {
        "id": "F0oBQ5evtzsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random sample tensor of shape (B, C, H, W) for the above 2D convolutional network\n",
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples = 1\n",
        "image_channel     = 1\n",
        "image_height      = 28\n",
        "image_width       = 28\n",
        "\n",
        "random_X              = torch.randn(number_of_samples, image_channel, image_width, image_height)\n",
        "print(f'input shape: \\n{random_X.shape}\\n')\n",
        "#print(f'input numbers: \\n{random_X.numpy()}\\n') # it will produce a large tensor of values\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = first_conv_2d(random_X)\n",
        "print(f'output shape: \\n{output.data.shape}\\n')\n",
        "#print(f'output layer value: \\n{output.data.numpy()}\\n') # it will produce a large tensor of values\n",
        "output_after_activation   = sigmoid_activation(output)\n",
        "print(f'No change in output shape after activation: \\n{output.data.shape}\\n')\n",
        "#print(f'output layer value (each number could have any value): \\n{output.data.numpy()}\\n')\n",
        "#print(f'Sigmoid activation value (each number must be within [0.0 to 1.0]): \\n{output_after_activation.data.numpy()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW53vin-tVaH",
        "outputId": "bb86421c-2b6a-4a81-c61b-878c37bf4353",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: \n",
            "torch.Size([1, 1, 28, 28])\n",
            "\n",
            "output shape: \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n",
            "No change in output shape after activation: \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using ReLU activation function**"
      ],
      "metadata": {
        "id": "3Ys-fzHCuqAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random sample tensor of shape (B, C, H, W) for the above 2D convolutional network\n",
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples = 1\n",
        "image_channel     = 1\n",
        "image_height      = 28\n",
        "image_width       = 28\n",
        "\n",
        "random_X              = torch.randn(number_of_samples, image_channel, image_width, image_height)\n",
        "print(f'input shape: \\n{random_X.shape}\\n')\n",
        "#print(f'input numbers: \\n{random_X.numpy()}\\n') # it will produce a large tensor of values\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = first_conv_2d(random_X)\n",
        "print(f'output shape: \\n{output.data.shape}\\n')\n",
        "#print(f'output layer value: \\n{output.data.numpy()}\\n') # it will produce a large tensor of values\n",
        "output_after_activation   = relu_activation(output)\n",
        "print(f'No change in output shape after activation: \\n{output.data.shape}\\n')\n",
        "#print(f'output layer value (each number could have any value): \\n{output.data.numpy()}\\n')\n",
        "#print(f'ReLU activation value (each number must be within [0.0 to infinity] NO NEGATIVE NUMBER): \\n{output_after_activation.data.numpy()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg-a_ZfpuiWl",
        "outputId": "49ddf233-52a7-4bf7-c17d-5dc3558c5c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: \n",
            "torch.Size([1, 1, 28, 28])\n",
            "\n",
            "output shape: \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n",
            "No change in output shape after activation: \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#3**\n",
        "\n",
        "> Experiment with different activation functions like sigmoid, and relu, and then pass a tensor through the linear layer you created for Group Exercises #1 and #2.\n",
        "\n",
        "> Take a look at the output shapes and values and make sure they match what you were expecting!"
      ],
      "metadata": {
        "id": "OuOPEOQVu7XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "87sDNOLDv3yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build a 3 layer convolutional neural network (CNN)!**\n",
        "\n",
        "First convolution layer has:\n",
        "  > its input volume has 3 channels (inputs are RGB color images)\n",
        "\n",
        "  > the output volume will have 64 channels\n",
        "\n",
        "  > each filter has a size of (3x3)\n",
        "\n",
        "Second convolution layer has:\n",
        "  > its input volume has 64 channels\n",
        "\n",
        "  > the output volume will have 128 channels\n",
        "\n",
        "  > each filter has a size of (3x3)\n"
      ],
      "metadata": {
        "id": "0h5ShXNNliD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction\n",
        "input_volume_channel_first    = 3\n",
        "output_volume_channel_first   = 32\n",
        "input_volume_channel_second   = 32\n",
        "output_volume_channel_second  = 128\n",
        "filter_size                   = 3\n",
        "\n",
        "first_conv_2d                 = nn.Conv2d(input_volume_channel_first, output_volume_channel_first, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "first_relu_activation         = nn.ReLU()\n",
        "second_conv_2d                = nn.Conv2d(input_volume_channel_second, output_volume_channel_second, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "second_relu_activation        = nn.ReLU()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sml5o0uepNvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **We can apply a tensor through the CNN layers now**"
      ],
      "metadata": {
        "id": "bN0-x03AlkfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random sample tensor of shape (B, C, H, W) for the above 2D convolutional network\n",
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples = 1\n",
        "image_channel     = 3\n",
        "image_height      = 28\n",
        "image_width       = 28\n",
        "\n",
        "random_X              = torch.randn(number_of_samples, image_channel, image_width, image_height)\n",
        "print(f'input shape: \\n{random_X.shape}\\n')\n",
        "#print(f'input numbers: \\n{random_X.numpy()}\\n') # it will produce a large tensor of values\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = first_conv_2d(random_X)\n",
        "print(f'First conv2d: output shape: \\n{output.data.shape}\\n')\n",
        "output                    = first_relu_activation(output)\n",
        "print(f'First activation: output shape (no change): \\n{output.data.shape}\\n')\n",
        "\n",
        "output                    = second_conv_2d(output)\n",
        "print(f'Second conv2d: output shape: \\n{output.data.shape}\\n')\n",
        "output                    = second_relu_activation(output)\n",
        "#print(f'output layer value: \\n{output.data.numpy()}\\n') # it will produce a large tensor of values\n",
        "print(f'Second activation: output shape (no change): \\n{output.data.shape}\\n')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12dr7m-Mj1in",
        "outputId": "38bb05c3-6876-4621-eecb-05700526f90e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: \n",
            "torch.Size([1, 3, 28, 28])\n",
            "\n",
            "First conv2d: output shape: \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n",
            "First activation: output shape (no change): \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n",
            "Second conv2d: output shape: \n",
            "torch.Size([1, 128, 24, 24])\n",
            "\n",
            "Second activation: output shape (no change): \n",
            "torch.Size([1, 128, 24, 24])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Group Exercise#4**\n",
        "Let's create a CNN with three conv2d layers and connect them in a sequence with the following structure:\n",
        "\n",
        "First convolution layer has:\n",
        "  > its input volume has 3 channels\n",
        "\n",
        "  > the output volume will be of 64 channels\n",
        "\n",
        "  > each filter has a size of (5x5)\n",
        "\n",
        "Second convolution layer has:\n",
        "  > its input volume has 64 channels\n",
        "\n",
        "  > the output volume will be of 128 channels\n",
        "\n",
        "  > each filter has a size of (5x5)\n",
        "\n",
        "Third convolution layer has:\n",
        "  > its input volume has 128 channels\n",
        "\n",
        "  > the output volume will be of 256 channels\n",
        "\n",
        "  > each filter has a size of (5x5)\n"
      ],
      "metadata": {
        "id": "Vn_XY5pRj_XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "nxie_gB-mOqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Group Exercise#5**\n",
        "> Apply a tensor through your CNN layers now."
      ],
      "metadata": {
        "id": "4ShpPaSFmSdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "ReH2hHydmnQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[MaxPool2d()](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n"
      ],
      "metadata": {
        "id": "Rwlt7K80XhfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction of a 2D max pooling layer (useful for feature map learning from the grid layouts of an image)\n",
        "\n",
        "# maxpool2d hyper-parameters\n",
        "pooling_filter_size         = 2\n",
        "\n",
        "# conv2d hyperparameters\n",
        "input_volume_channel_first  = 3\n",
        "output_volume_channel_first = 64\n",
        "conv_filter_size            = 3\n",
        "\n",
        "\n",
        "first_conv_2d               = nn.Conv2d(input_volume_channel_first, output_volume_channel_first, conv_filter_size)  # 2D convolutional transformation module :input_volume_channel=3, output_volume_channel=32, filter_size= (3x3)\n",
        "relu_activation             = nn.ReLU()\n",
        "maxpool_layer               = nn.MaxPool2d(pooling_filter_size, stride=2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JRyywyxaXrmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **We can apply a tensor through the Conv2d -> ReLU -> MaxPool2d layers now**"
      ],
      "metadata": {
        "id": "dTPXe4emY3io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random sample tensor of shape (B, C, H, W) for the above 2D convolutional network\n",
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples = 1\n",
        "image_channel     = 3\n",
        "image_height      = 28\n",
        "image_width       = 28\n",
        "\n",
        "random_X              = torch.randn(number_of_samples, image_channel, image_width, image_height)\n",
        "print(f'input shape: \\n{random_X.shape}\\n')\n",
        "#print(f'input numbers: \\n{random_X.numpy()}\\n') # it will produce a large tensor of values\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = first_conv_2d(random_X)\n",
        "print(f'Conv2d: output shape: \\n{output.data.shape}\\n')\n",
        "output                    = relu_activation(output)\n",
        "print(f'ReLU activation: output shape (no change): \\n{output.data.shape}\\n')\n",
        "output                    = maxpool_layer(output)\n",
        "print(f'MaxPool2d: output shape: \\n{output.data.shape}\\n')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWgu_2FuYz4e",
        "outputId": "c4bd64e1-7fe7-4577-b037-7bfecafcd67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: \n",
            "torch.Size([1, 3, 28, 28])\n",
            "\n",
            "Conv2d: output shape: \n",
            "torch.Size([1, 64, 26, 26])\n",
            "\n",
            "ReLU activation: output shape (no change): \n",
            "torch.Size([1, 64, 26, 26])\n",
            "\n",
            "MaxPool2d: output shape: \n",
            "torch.Size([1, 64, 13, 13])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **You can build your CNN (eg, Conv2d -> ReLU -> MaxPool2d layers) using nn.Sequential() module**\n",
        "\n",
        "> [nn.Sequential()](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)"
      ],
      "metadata": {
        "id": "1jB26xd5k96r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can also create a single module using nn.Sequential() as follows:\n",
        "# advantage: simple code but you won't be able to see intermediate output shapes\n",
        "my_cnn = nn.Sequential( nn.Conv2d(input_volume_channel_first, output_volume_channel_first, conv_filter_size),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(pooling_filter_size, stride=2))\n",
        "\n",
        "\n",
        "print(f'full   CNN  : \\n------------------\\n{my_cnn}\\n------------------\\n')\n",
        "print(f'first  layer: \\n{my_cnn[0]}\\n------------------')\n",
        "print(f'second layer: \\n{my_cnn[1]}\\n------------------')\n",
        "print(f'third  layer: \\n{my_cnn[2]}\\n------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLc7c259kwt8",
        "outputId": "09533d3c-5785-46d4-ae37-5b5147d1210f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full   CNN  : \n",
            "------------------\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "------------------\n",
            "\n",
            "first  layer: \n",
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "------------------\n",
            "second layer: \n",
            "ReLU()\n",
            "------------------\n",
            "third  layer: \n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can apply everything at once using one call\n",
        "output = my_cnn(random_X)\n",
        "print(f'Final (MaxPool2d): output shape: \\n{output.data.shape}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqRQuZCDlX6V",
        "outputId": "0eb67039-1799-49b0-9c53-5e00df802484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final (MaxPool2d): output shape: \n",
            "torch.Size([1, 64, 26, 26])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# individually you can also apply forward pass using different indices\n",
        "output = my_cnn[0](random_X)\n",
        "print(f'output shape: \\n{output.data.shape}\\n')\n",
        "output = my_cnn[1](output)\n",
        "print(f'output shape: \\n{output.data.shape}\\n')\n",
        "output = my_cnn[2](output)\n",
        "print(f'output shape: \\n{output.data.shape}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDIXJUR8nBRc",
        "outputId": "e4963c69-af1d-43ba-a0d4-e09209d2e92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape: \n",
            "torch.Size([1, 64, 26, 26])\n",
            "\n",
            "output shape: \n",
            "torch.Size([1, 64, 26, 26])\n",
            "\n",
            "output shape: \n",
            "torch.Size([1, 64, 13, 13])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vu4xeng2lXq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Group Exercise#6**\n",
        "> Replace your MaxPool2d with AvgPool2d and redo the experiment.\n",
        "\n",
        "> [AvgPool2d()](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html)"
      ],
      "metadata": {
        "id": "28QDIYlEZT-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "clmUnbDiXWqM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}